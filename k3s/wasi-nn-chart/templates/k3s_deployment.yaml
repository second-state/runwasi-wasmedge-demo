apiVersion: apps/v1
kind: Deployment
metadata:
  name: llama-api-server
spec:
  replicas: 1
  selector:
    matchLabels:
      app: llama-api-server
  template:
    metadata:
      labels:
        app: llama-api-server
    spec:
      runtimeClassName: wasmedge
      containers:
        - name: llama-api-server
          image: ghcr.io/second-state/llama-api-server:latest
          imagePullPolicy: Never
          command: ["llama-api-server.wasm"]
          args:
            - "--prompt-template"
            - "llama-3-chat"
            - "--ctx-size"
            - "4096"
            - "--model-name"
            - "llama-3-1b"
          env:
            - name: WASMEDGE_PLUGIN_PATH
              value: "{{ .Values.paths.wasi_nn_plugin_file_dir }}"
            - name: LD_LIBRARY_PATH
              value: "{{ .Values.paths.wasi_nn_plugin_lib_dir }}"
            - name: WASMEDGE_WASINN_PRELOAD
              value: "default:GGML:CPU:/home/runner/models/Llama-3.2-1B-Instruct-Q5_K_M.gguf"
          volumeMounts:
            - name: gguf-model-file
              mountPath: /home/runner/models/Llama-3.2-1B-Instruct-Q5_K_M.gguf
              readOnly: true
            - name: wasi-nn-plugin-file
              mountPath: {{ .Values.paths.wasi_nn_plugin_file }}
              readOnly: true
            - name: wasi-nn-plugin-lib-dir
              mountPath: {{ .Values.paths.wasi_nn_plugin_lib_dir }}
              readOnly: true
{{- range .Values.systemLibs }}
            - name: {{ .name }}
              mountPath: {{ .hostPath }}
              readOnly: true
{{- end }}
      volumes:
        - name: gguf-model-file
          hostPath:
            path: /home/runner/models/Llama-3.2-1B-Instruct-Q5_K_M.gguf
            type: File
        - name: wasi-nn-plugin-file
          hostPath:
            path: {{ .Values.paths.wasi_nn_plugin_file }}
            type: File
        - name: wasi-nn-plugin-lib-dir
          hostPath:
            path: {{ .Values.paths.wasi_nn_plugin_lib_dir }}
            type: Directory
{{- range .Values.systemLibs }}
        - name: {{ .name }}
          hostPath:
            path: {{ .hostPath }}
            type: File
{{- end }}

---
apiVersion: v1
kind: Service
metadata:
  name: llama-api-server-service
spec:
  selector:
    app: llama-api-server
  ports:
    - protocol: TCP
      port: 8080
      targetPort: 8080
  type: ClusterIP

---
apiVersion: node.k8s.io/v1
kind: RuntimeClass
metadata:
  name: wasmedge
handler: wasmedge